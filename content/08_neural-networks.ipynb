{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be0f472-ae34-4944-9dab-396c01de824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import src\n",
    "\n",
    "primary, accent = src.theme.set()\n",
    "pal = sns.color_palette(\"wfondrie\")\n",
    "\n",
    "def save(fname):\n",
    "    \"\"\"Save the figures\"\"\"\n",
    "    figures = Path(\"figures\")\n",
    "    figures.mkdir(exist_ok=True)\n",
    "    if not fname.startswith(\"08_\"):\n",
    "        fname = \"08_\" + fname\n",
    "        \n",
    "    if not fname.endswith(\".png\"):\n",
    "        fname += \".png\"\n",
    "    \n",
    "    plt.tight_layout(pad=0.2)\n",
    "    plt.savefig(figures / fname, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20072731-24c6-43ab-a8ca-5a286e479cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-5, 5)\n",
    "\n",
    "def relu(X):\n",
    "    X = X.copy()\n",
    "    X[X <= 0] = 0\n",
    "    return X\n",
    "\n",
    "def sigmoid(X):\n",
    "    return np.exp(X) / (1 + np.exp(X))\n",
    "\n",
    "def tanh(X):\n",
    "    return np.tanh(X)\n",
    "\n",
    "funcs = [relu, sigmoid, tanh]\n",
    "labs = [\"ReLU(X)\", \"Sigmoid(X)\", \"Tanh(X)\"]\n",
    "for func, lab in zip(funcs, labs):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.plot(X, func(X))\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(lab)\n",
    "    stem = lab.replace(\"(X)\", \"\").lower()\n",
    "    save(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2fc16-37df-4ce4-b1a9-79da42b70807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def grad_example(fname, start=None, n_iter=10, lr=1):\n",
    "    def f(X):\n",
    "        return (X*(X**2-20)*(X-1.5) + 200) / 300\n",
    "    \n",
    "    def mk_axes():\n",
    "        X = torch.linspace(-5, 5, 100, requires_grad=True)\n",
    "        L = f(X)\n",
    "        L_grad = torch.ones_like(X)\n",
    "        L.backward(gradient=L_grad)\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(9, 4))\n",
    "        axs[0].plot(X.detach().numpy(), L.detach().numpy())\n",
    "        axs[1].plot(X.detach().numpy(), X.grad)\n",
    "        axs[0].set_ylabel(\"Loss\")\n",
    "        axs[1].set_ylabel(\"Gradient\")\n",
    "        axs[1].axhline(0, linestyle=\"dashed\", color=primary, zorder=1)\n",
    "        axs[0].annotate(\n",
    "            f\"Learning Rate = {lr:.2f}\", \n",
    "            (0.98, 0.98),\n",
    "            xycoords=\"axes fraction\", \n",
    "            ha=\"right\",\n",
    "            va=\"top\",\n",
    "            fontsize=\"large\",\n",
    "        )\n",
    "        for ax in axs:\n",
    "            ax.set_xlabel(\"Parameter value\")\n",
    "        \n",
    "        return axs\n",
    "    \n",
    "    if start is None:\n",
    "        axs = mk_axes()\n",
    "        save(fname)\n",
    "        return axs\n",
    "    \n",
    "    prev_X = []\n",
    "    prev_L = []\n",
    "    prev_G = []\n",
    "    X = torch.tensor(start, requires_grad=True, dtype=float)\n",
    "    for i in range(n_iter):\n",
    "        axs = mk_axes()\n",
    "        L = f(X)\n",
    "        L.backward()\n",
    "        prev_X.append(X.detach().item())\n",
    "        prev_L.append(L.detach().item())\n",
    "        prev_G.append(X.grad.item())\n",
    "        \n",
    "        sns.scatterplot(x=prev_X, y=prev_L, color=primary, zorder=5, ax=axs[0])\n",
    "        axs[0].plot(prev_X, prev_L, c=primary, zorder=5)\n",
    "        sns.scatterplot(x=prev_X, y=prev_G, color=primary, zorder=5, ax=axs[1])\n",
    "        axs[1].plot(prev_X, prev_G, c=primary, zorder=5)\n",
    "        save(f\"{fname}_{str(i).zfill(2)}\")\n",
    "        step = -X.grad * lr\n",
    "        with torch.no_grad():\n",
    "            X += step\n",
    "            X.grad.detach_()\n",
    "            X.grad.zero_()\n",
    "        \n",
    "    return axs\n",
    "        \n",
    "\n",
    "grad_example(\"gd_blank\")\n",
    "grad_example(\"gd_left\", -5, 6, 1)\n",
    "grad_example(\"gd_left-fast\", -5, 6, 5)\n",
    "grad_example(\"gd_right\", 5, 6, 1)\n",
    "grad_example(\"gd_fast\", 5, 10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebb884-5e3b-424a-9c11-fbd0d5a6113f",
   "metadata": {},
   "source": [
    "## LR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535920d-ef25-4371-bd64-ab1e88313d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
